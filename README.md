# Large Language Models (LLMs) for Extracting Moral Foundation Values from Text
This is a repo for LLMs measuring moral foundation values in multilingual contexts. It includes several parts: 
1. notes for LLM workshop
2. notes and codes for NUS LLM paper 

# Project Plan
* __Paper 1.__ Replicate the research design of [The Validity of Sentiment Analysis: Comparing Manual Annotation, Crowd-Coding, Dictionary Approaches, and Machine Learning Algorithms](https://doi.org/10.1080/19312458.2020.1869198). this is a methodology paper
* __Paper 2.__ LLMs Education tutorial. This is a case-study discussion paper, discuss the performance and ethical concerns of LLMs in coding moral foundation values

## Paper 1. The Validity of Multilingual Moral Foundation Analysis: Comparing Manual Annotation, Crowd-Coding, Dictionary Approaches, Machine/Deep Learning Algorithms and Large Language Models

`multi-lingual` is the keyword in the paper

### Research Design 
1. Introduction: the ultimate goal is to evaluate the `best approach` of coding moral foundation values from text in `multilingual` contexts
2. Literature Review
    1. existing methods of moral foundation measurements `across languages`
    2. 
3. Methods and Comparison
    1. dataset selection: domain, language, size, platform?
    2. gold standard 
    3. manual coding
    4. crowd coding
    5. moral foundation dictionaries 
    6. machine learning - multilingual embedding models 
        1. where to position `FrameAix`?
        2. how to understand `BERT` series models?
    7. LLMs 
        1. embedding models? or chat models?
        2. how many chat models should i use? `GPT-3.5-turbo` and `Llama`
        3. different performance across languages?
        4. hallucination issues (lessons we should aware)
4. ultimate goal - recommendations the best practice (hopefully LLMs) for multilingual moral foundation classifications


###